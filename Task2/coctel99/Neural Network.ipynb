{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Gradient check passed!\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Gradient check passed!\nGradient check passed!\nGradient check passed!\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Checking gradient for layer1.W\n",
      "Gradient check passed!\nChecking gradient for layer1.B\nGradient check passed!\nChecking gradient for layer3.W\nGradient check passed!\nChecking gradient for layer3.B\nGradient check passed!\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 6
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Checking gradient for layer1.W\n",
      "Gradient check passed!\nChecking gradient for layer1.B\nGradient check passed!\nChecking gradient for layer3.W\nGradient check passed!\nChecking gradient for layer3.B\nGradient check passed!\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 7
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.1"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 8
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки\n",
    "\n",
    "Если все реализовано корректно, значение функции ошибки должно уменьшаться с каждой эпохой, пусть и медленно. Не беспокойтесь пока про validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Loss: 2.217057, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.157437, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.115648, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287707, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.176635, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.070778, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.389343, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.201810, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.268138, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.177243, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.188959, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.288565, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.324022, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277031, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.376680, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.181966, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.288749, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.281310, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.245181, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.235221, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate = 1e-2)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x10867a88>]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 10
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAQXElEQVR4nO3df6zddX3H8edrrSxx8yctgrQd1dRtnSuOHKtzKqLTtMRRNdkCI6yJxKZGNjExswsJ05gl/tqW/YCRDpuxxYgaUbtFhsQs7o+urrcEkIpABZRahIJEtriJne/9cb+449m5vd/b++O0/Twfycn9fr+fz+d73t/P/fa+7vd7zulNVSFJas/PTLoASdJkGACS1CgDQJIaZQBIUqMMAElq1PJJFzAXK1asqHPOOWfSZUjSSWX//v2PVdXK0e0nVQCcc845TE1NTboMSTqpJPnWuO3eApKkRhkAktQoA0CSGmUASFKjDABJalSvAEiyKck9SQ4m2TGm/dIkd3aPPUnO7TM2ye93bQeSfGT+hyNJ6mvWt4EmWQZcA7wROATsS7K7qr4+1O0B4PyqeiLJZmAn8IpjjU1yAbAF2FBVP0xyxsIemiTpWPp8DmAjcLCq7gdIciPTP7h/EgBVtWeo/15gVY+x7wQ+VFU/7Pbx6PwO5Rhu3gHf/dqi7V6SFt2ZvwqbP7Sgu+xzC+hs4KGh9UPdtplcDtzcY+xLgNck+WqSryR5+bidJdmWZCrJ1JEjR3qUK0nqo88VQMZsG/tXZLrbOpcDr+4xdjnwPOCVwMuBTyd5UY38hZqq2sn0LSUGg8Hx/fWaBU5NSToV9LkCOASsHlpfBRwe7ZRkA3A9sKWqHu8x9hBwU037d+DHwIq5lS9JOl59AmAfsC7J2iSnARcDu4c7JFkD3ARcVlX39hz7eeD13fiXAKcBj83nYCRJ/c16C6iqjia5ArgFWAbsqqoDSbZ37dcBVwOnA9cmAThaVYOZxna73gXsSnIX8BSwdfT2jyRp8eRk+pk7GAzK/w1UkuYmyf6qGoxu95PAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUqF4BkGRTknuSHEyyY0z7pUnu7B57kpw7h7HvTVJJVszvUCRJczFrACRZBlwDbAbWA5ckWT/S7QHg/KraAHwQ2NlnbJLVwBuBb8//UCRJc9HnCmAjcLCq7q+qp4AbgS3DHapqT1U90a3uBVb1HPvnwB8CNY9jkCQdhz4BcDbw0ND6oW7bTC4Hbp5tbJKLgO9U1R29q5UkLZjlPfpkzLaxv7EnuYDpAHj1scYmeSZwFfCmWZ882QZsA1izZk2PciVJffS5AjgErB5aXwUcHu2UZANwPbClqh6fZeyLgbXAHUke7LbfluTM0f1W1c6qGlTVYOXKlT3KlST10ecKYB+wLsla4DvAxcDvDndIsga4Cbisqu6dbWxVHQDOGBr/IDCoqsfmcSySpDmYNQCq6miSK4BbgGXArqo6kGR7134dcDVwOnBtEoCj3W/tY8cu0rFIkuYgVSfPG3AGg0FNTU1NugxJOqkk2V9Vg9HtfhJYkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqN6BUCSTUnuSXIwyY4x7ZcmubN77Ely7mxjk3w0yTe6MZ9L8tyFOSRJUh+zBkCSZcA1wGZgPXBJkvUj3R4Azq+qDcAHgZ09xt4KvLQbcy/wR/M/HElSX32uADYCB6vq/qp6CrgR2DLcoar2VNUT3epeYNVsY6vqS1V1dMwYSdIS6BMAZwMPDa0f6rbN5HLg5jmOffvQmJ+SZFuSqSRTR44c6VGuJKmPPgGQMdtqbMfkAqYD4H19xya5CjgKfGLcPqtqZ1UNqmqwcuXKHuVKkvpY3qPPIWD10Poq4PBopyQbgOuBzVX1eJ+xSbYCbwbeUFVjQ0WStDj6XAHsA9YlWZvkNOBiYPdwhyRrgJuAy6rq3j5jk2xi+krhoqr6wfwPRZI0F7NeAVTV0SRXALcAy4BdVXUgyfau/TrgauB04NokAEe72zZjx3a7/mvgZ4FbuzF7q2r7wh6eJGkmOZnuvAwGg5qampp0GZJ0Ukmyv6oGo9v9JLAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDWqVwAk2ZTkniQHk+wY035pkju7x54k5842Nsnzk9ya5L7u6/MW5pAkSX3MGgBJlgHXAJuB9cAlSdaPdHsAOL+qNgAfBHb2GLsD+HJVrQO+3K1LkpZInyuAjcDBqrq/qp4CbgS2DHeoqj1V9US3uhdY1WPsFuCGbvkG4C3HfxiSpLnqEwBnAw8NrR/qts3kcuDmHmNfUFUPA3Rfzxi3syTbkkwlmTpy5EiPciVJffQJgIzZVmM7JhcwHQDvm+vYmVTVzqoaVNVg5cqVcxkqSTqGPgFwCFg9tL4KODzaKckG4HpgS1U93mPsI0nO6saeBTw6t9IlSfPRJwD2AeuSrE1yGnAxsHu4Q5I1wE3AZVV1b8+xu4Gt3fJW4AvHfxiSpLlaPluHqjqa5ArgFmAZsKuqDiTZ3rVfB1wNnA5cmwTgaHfbZuzYbtcfAj6d5HLg28BvL/CxSZKOIVVzuiU/UYPBoKampiZdhiSdVJLsr6rB6HY/CSxJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUb0CIMmmJPckOZhkx5j2X0ryb0l+mOS9I23vTnJXkgNJrhza/rIke5PcnmQqycb5H44kqa9ZAyDJMuAaYDOwHrgkyfqRbt8D/gD42MjYlwLvADYC5wJvTrKua/4I8IGqehlwdbcuSVoifa4ANgIHq+r+qnoKuBHYMtyhqh6tqn3Aj0bG/jKwt6p+UFVHga8Ab316GPDsbvk5wOHjPAZJ0nFY3qPP2cBDQ+uHgFf03P9dwJ8kOR34L+BCYKpruxK4JcnHmA6iV43bQZJtwDaANWvW9HxaSdJs+lwBZMy26rPzqrob+DBwK/DPwB3A0a75ncB7qmo18B7g4zPsY2dVDapqsHLlyj5PK0nqoU8AHAJWD62vYg63a6rq41V1XlW9lunXCu7rmrYCN3XLn2H6VpMkaYn0CYB9wLoka5OcBlwM7O77BEnO6L6uAd4GfLJrOgyc3y2/nv8LBknSEpj1NYCqOprkCuAWYBmwq6oOJNnetV+X5Eym7+0/G/hx93bP9VX1JPDZ7jWAHwHvqqonul2/A/iLJMuB/6a7zy9JWhqp6nU7/4QwGAxqampq9o6SpJ9Isr+qBqPb/SSwJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqOWT7qApfCBfzzA1w8/OekyJOm4rX/hs/nj3/qVBd2nVwCS1KgmrgAWOjUl6VTgFYAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUamqSdfQW5IjwLeOc/gK4LEFLGehWd/8WN/8WN/8ncg1/kJVrRzdeFIFwHwkmaqqwaTrmIn1zY/1zY/1zd/JUOMobwFJUqMMAElqVEsBsHPSBczC+ubH+ubH+ubvZKjxpzTzGoAk6ae1dAUgSRpiAEhSo065AEiyKck9SQ4m2TGmPUn+smu/M8l5S1jb6iT/kuTuJAeSvHtMn9cl+X6S27vH1UtVX/f8Dyb5WvfcU2PaJzl/vzg0L7cneTLJlSN9lnT+kuxK8miSu4a2PT/JrUnu674+b4axxzxXF7G+jyb5Rvf9+1yS584w9pjnwiLW9/4k3xn6Hl44w9hJzd+nhmp7MMntM4xd9Pmbt6o6ZR7AMuCbwIuA04A7gPUjfS4EbgYCvBL46hLWdxZwXrf8LODeMfW9DvinCc7hg8CKY7RPbP7GfK+/y/QHXCY2f8BrgfOAu4a2fQTY0S3vAD48Q/3HPFcXsb43Acu75Q+Pq6/PubCI9b0feG+P7/9E5m+k/U+Bqyc1f/N9nGpXABuBg1V1f1U9BdwIbBnpswX4+5q2F3hukrOWoriqeriqbuuW/wO4Gzh7KZ57AU1s/ka8AfhmVR3vJ8MXRFX9K/C9kc1bgBu65RuAt4wZ2udcXZT6qupLVXW0W90LrFro5+1rhvnrY2Lz97QkAX4H+ORCP+9SOdUC4GzgoaH1Q/z/H7B9+iy6JOcAvwZ8dUzzrye5I8nNSZb6DxoX8KUk+5NsG9N+QswfcDEz/8Ob5PwBvKCqHobp0AfOGNPnRJnHtzN9RTfObOfCYrqiu0W1a4ZbaCfC/L0GeKSq7puhfZLz18upFgAZs230fa59+iyqJD8PfBa4sqqeHGm+jenbGucCfwV8filrA36jqs4DNgPvSvLakfYTYf5OAy4CPjOmedLz19eJMI9XAUeBT8zQZbZzYbH8DfBi4GXAw0zfZhk18fkDLuHYv/1Pav56O9UC4BCwemh9FXD4OPosmiTPYPqH/yeq6qbR9qp6sqr+s1v+IvCMJCuWqr6qOtx9fRT4HNOX2sMmOn+dzcBtVfXIaMOk56/zyNO3xbqvj47pM+nzcCvwZuDS6m5Yj+pxLiyKqnqkqv6nqn4M/O0Mzzvp+VsOvA341Ex9JjV/c3GqBcA+YF2Std1viRcDu0f67AZ+r3s3yyuB7z99ub7YunuGHwfurqo/m6HPmV0/kmxk+nv0+BLV93NJnvX0MtMvFt410m1i8zdkxt+8Jjl/Q3YDW7vlrcAXxvTpc64uiiSbgPcBF1XVD2bo0+dcWKz6hl9TeusMzzux+ev8JvCNqjo0rnGS8zcnk34VeqEfTL9L5V6m3yFwVbdtO7C9Ww5wTdf+NWCwhLW9munL1DuB27vHhSP1XQEcYPpdDXuBVy1hfS/qnveOroYTav66538m0z/QnzO0bWLzx3QQPQz8iOnfSi8HTge+DNzXfX1+1/eFwBePda4uUX0Hmb5//vQ5eN1ofTOdC0tU3z9059adTP9QP+tEmr9u+989fc4N9V3y+Zvvw/8KQpIadardApIk9WQASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEb9LyLyCnUvyNa0AAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Loss: 2.250718, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.369508, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.209910, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.258537, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.188416, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.205064, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.126148, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.319578, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.325751, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.320998, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.175592, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.265976, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.363186, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.131519, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.410504, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.228590, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.294455, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.242233, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.233189, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.213630, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Loss: 2.321504, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.305573, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.315005, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.249502, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.255664, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.300977, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.243300, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.259131, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.240870, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.256889, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.250501, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.305861, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.215956, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277011, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.266154, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.247150, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.248955, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.205055, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.180664, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.308770, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-4, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Loss: 2.351618, Train accuracy: 0.266667, val accuracy: 0.066667\nLoss: 2.318467, Train accuracy: 0.266667, val accuracy: 0.066667\nLoss: 2.291136, Train accuracy: 0.200000, val accuracy: 0.066667\nLoss: 2.341864, Train accuracy: 0.200000, val accuracy: 0.133333",
      "\nLoss: 2.302463, Train accuracy: 0.200000, val accuracy: 0.066667\nLoss: 2.319034, Train accuracy: 0.200000, val accuracy: 0.066667\nLoss: 2.235521, Train accuracy: 0.200000, val accuracy: 0.066667\nLoss: 2.170412, Train accuracy: 0.266667, val accuracy: 0.000000\nLoss: 2.144598, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.000302, Train accuracy: 0.400000, val accuracy: 0.000000\nLoss: 1.842682, Train accuracy: 0.400000, val accuracy: 0.000000\nLoss: 2.238035, Train accuracy: 0.400000, val accuracy: 0.000000\nLoss: 1.616099, Train accuracy: 0.400000, val accuracy: 0.000000\nLoss: 2.203432, Train accuracy: 0.400000, val accuracy: 0.000000\nLoss: 1.902569, Train accuracy: 0.400000, val accuracy: 0.000000\nLoss: 1.637197, Train accuracy: 0.400000, val accuracy: 0.000000\nLoss: 2.003430, Train accuracy: 0.400000, val accuracy: 0.000000\nLoss: 1.394373, Train accuracy: 0.400000, val accuracy: 0.000000\nLoss: 1.492224, Train accuracy: 0.400000, val accuracy: 0.000000\nLoss: 1.807273, Train accuracy: 0.466667, val accuracy: 0.000000",
      "\nLoss: 2.022181, Train accuracy: 0.400000, val accuracy: 0.000000\nLoss: 1.577554, Train accuracy: 0.466667, val accuracy: 0.000000\nLoss: 1.866207, Train accuracy: 0.400000, val accuracy: 0.066667\nLoss: 1.908744, Train accuracy: 0.466667, val accuracy: 0.066667\nLoss: 1.159965, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 2.083456, Train accuracy: 0.466667, val accuracy: 0.066667\nLoss: 1.642604, Train accuracy: 0.466667, val accuracy: 0.066667\nLoss: 2.125341, Train accuracy: 0.466667, val accuracy: 0.066667\nLoss: 1.993812, Train accuracy: 0.466667, val accuracy: 0.066667\nLoss: 1.343383, Train accuracy: 0.466667, val accuracy: 0.000000\nLoss: 1.837536, Train accuracy: 0.600000, val accuracy: 0.000000\nLoss: 1.609352, Train accuracy: 0.533333, val accuracy: 0.000000\nLoss: 1.314199, Train accuracy: 0.533333, val accuracy: 0.066667\nLoss: 1.798446, Train accuracy: 0.600000, val accuracy: 0.066667",
      "\nLoss: 1.659346, Train accuracy: 0.600000, val accuracy: 0.000000\nLoss: 1.933030, Train accuracy: 0.600000, val accuracy: 0.000000\nLoss: 1.083985, Train accuracy: 0.600000, val accuracy: 0.066667\nLoss: 1.491238, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.731915, Train accuracy: 0.600000, val accuracy: 0.000000\nLoss: 1.788430, Train accuracy: 0.666667, val accuracy: 0.000000\nLoss: 2.425725, Train accuracy: 0.666667, val accuracy: 0.000000\nLoss: 1.017317, Train accuracy: 0.666667, val accuracy: 0.000000\nLoss: 1.558682, Train accuracy: 0.666667, val accuracy: 0.000000\nLoss: 1.728849, Train accuracy: 0.666667, val accuracy: 0.000000\nLoss: 1.452117, Train accuracy: 0.666667, val accuracy: 0.066667\nLoss: 1.861666, Train accuracy: 0.666667, val accuracy: 0.000000\nLoss: 1.198709, Train accuracy: 0.733333, val accuracy: 0.000000\nLoss: 1.657933, Train accuracy: 0.733333, val accuracy: 0.000000",
      "\nLoss: 1.558153, Train accuracy: 0.733333, val accuracy: 0.000000\nLoss: 1.384778, Train accuracy: 0.800000, val accuracy: 0.133333\n",
      "Loss: 1.625072, Train accuracy: 0.733333, val accuracy: 0.000000\nLoss: 1.549759, Train accuracy: 0.800000, val accuracy: 0.000000\nLoss: 1.617123, Train accuracy: 0.800000, val accuracy: 0.000000\nLoss: 1.739898, Train accuracy: 0.800000, val accuracy: 0.000000\nLoss: 1.417619, Train accuracy: 0.800000, val accuracy: 0.000000\nLoss: 1.533807, Train accuracy: 0.800000, val accuracy: 0.133333\nLoss: 1.011228, Train accuracy: 0.733333, val accuracy: 0.000000\nLoss: 0.936917, Train accuracy: 0.800000, val accuracy: 0.000000\nLoss: 1.408309, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.036403, Train accuracy: 0.800000, val accuracy: 0.066667\nLoss: 1.865917, Train accuracy: 0.800000, val accuracy: 0.000000\nLoss: 1.592674, Train accuracy: 0.800000, val accuracy: 0.000000\nLoss: 1.323204, Train accuracy: 0.800000, val accuracy: 0.000000\nLoss: 1.334323, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.938533, Train accuracy: 0.800000, val accuracy: 0.066667\nLoss: 1.275339, Train accuracy: 0.800000, val accuracy: 0.066667\nLoss: 1.253094, Train accuracy: 0.800000, val accuracy: 0.000000\nLoss: 0.897369, Train accuracy: 0.800000, val accuracy: 0.000000\nLoss: 1.138715, Train accuracy: 0.800000, val accuracy: 0.000000\nLoss: 1.601602, Train accuracy: 0.800000, val accuracy: 0.066667\nLoss: 1.564878, Train accuracy: 0.800000, val accuracy: 0.000000\nLoss: 1.059963, Train accuracy: 0.800000, val accuracy: 0.000000\nLoss: 1.502392, Train accuracy: 0.800000, val accuracy: 0.000000\nLoss: 1.681630, Train accuracy: 0.800000, val accuracy: 0.000000",
      "\nLoss: 1.228649, Train accuracy: 0.800000, val accuracy: 0.000000\nLoss: 1.550753, Train accuracy: 0.800000, val accuracy: 0.000000\nLoss: 1.786590, Train accuracy: 0.800000, val accuracy: 0.000000\nLoss: 1.226258, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.957398, Train accuracy: 0.800000, val accuracy: 0.066667\nLoss: 1.442177, Train accuracy: 0.800000, val accuracy: 0.066667\nLoss: 1.435122, Train accuracy: 0.800000, val accuracy: 0.000000\nLoss: 1.106624, Train accuracy: 0.800000, val accuracy: 0.000000\nLoss: 1.231636, Train accuracy: 0.800000, val accuracy: 0.000000\nLoss: 1.457298, Train accuracy: 0.800000, val accuracy: 0.000000\nLoss: 0.921533, Train accuracy: 0.800000, val accuracy: 0.000000\nLoss: 1.184508, Train accuracy: 0.866667, val accuracy: 0.000000\nLoss: 1.222668, Train accuracy: 0.800000, val accuracy: 0.000000\nLoss: 0.944016, Train accuracy: 0.866667, val accuracy: 0.000000\nLoss: 1.295791, Train accuracy: 0.866667, val accuracy: 0.000000",
      "\nLoss: 1.478291, Train accuracy: 0.866667, val accuracy: 0.000000\nLoss: 1.294451, Train accuracy: 0.866667, val accuracy: 0.000000\nLoss: 1.375229, Train accuracy: 0.866667, val accuracy: 0.000000\nLoss: 1.415711, Train accuracy: 0.933333, val accuracy: 0.000000\nLoss: 1.056241, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.258684, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.131832, Train accuracy: 0.933333, val accuracy: 0.000000\nLoss: 1.053068, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.455916, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.092817, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.412114, Train accuracy: 1.000000, val accuracy: 0.066667\nLoss: 1.628100, Train accuracy: 1.000000, val accuracy: 0.066667\nLoss: 1.204674, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.558378, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.095451, Train accuracy: 1.000000, val accuracy: 0.066667\nLoss: 1.280285, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.103288, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.309781, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.369390, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.174232, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.173103, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.323319, Train accuracy: 1.000000, val accuracy: 0.066667\nLoss: 1.167392, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.076201, Train accuracy: 1.000000, val accuracy: 0.066667\nLoss: 1.232961, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.157558, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.330180, Train accuracy: 1.000000, val accuracy: 0.066667",
      "\nLoss: 1.283642, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.163123, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.331565, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.404167, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.188150, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.441295, Train accuracy: 1.000000, val accuracy: 0.066667\nLoss: 1.068600, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.364755, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.212599, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.128207, Train accuracy: 1.000000, val accuracy: 0.066667\nLoss: 1.121540, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.024118, Train accuracy: 1.000000, val accuracy: 0.066667",
      "\nLoss: 0.939308, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.422518, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.381779, Train accuracy: 1.000000, val accuracy: 0.066667\nLoss: 1.321666, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.138238, Train accuracy: 1.000000, val accuracy: 0.066667\nLoss: 1.135899, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.166023, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.297579, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.133557, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.212286, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.282922, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.026195, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.237881, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.280440, Train accuracy: 1.000000, val accuracy: 0.066667\nLoss: 1.126200, Train accuracy: 1.000000, val accuracy: 0.000000",
      "\nLoss: 1.263944, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.136968, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.371337, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.229599, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.242691, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.263285, Train accuracy: 1.000000, val accuracy: 0.000000\nLoss: 1.274737, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Loss: 2.300068, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.276836, Train accuracy: 0.200000, val accuracy: 0.133333\nLoss: 2.117664, Train accuracy: 0.200000, val accuracy: 0.133333\nLoss: 2.180422, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 2.134509, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.621801, Train accuracy: 0.333333, val accuracy: 0.066667\nLoss: 1.425448, Train accuracy: 0.466667, val accuracy: 0.066667\nLoss: 1.636224, Train accuracy: 0.466667, val accuracy: 0.000000\nLoss: 2.011408, Train accuracy: 0.600000, val accuracy: 0.066667\nLoss: 1.664447, Train accuracy: 0.733333, val accuracy: 0.066667\nLoss: 1.110580, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 0.871699, Train accuracy: 0.866667, val accuracy: 0.133333\nLoss: 0.474149, Train accuracy: 1.000000, val accuracy: 0.000000",
      "\n",
      "Loss: 0.380918, Train accuracy: 0.866667, val accuracy: 0.000000\nLoss: 0.475413, Train accuracy: 0.933333, val accuracy: 0.000000",
      "\nLoss: 0.565075, Train accuracy: 0.800000, val accuracy: 0.000000\nLoss: 0.949572, Train accuracy: 0.800000, val accuracy: 0.066667\nLoss: 35.699035, Train accuracy: 0.800000, val accuracy: 0.066667\nLoss: 7.852720, Train accuracy: 0.533333, val accuracy: 0.133333\nLoss: 2.218685, Train accuracy: 0.533333, val accuracy: 0.066667\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-2)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-1, num_epochs=20, batch_size=5)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **60%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Loss: 2.219790, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.088635, Train accuracy: 0.264000, val accuracy: 0.267000\n",
      "Loss: 1.783668, Train accuracy: 0.440667, val accuracy: 0.444000\n",
      "Loss: 1.576490, Train accuracy: 0.552889, val accuracy: 0.539000\n",
      "Loss: 1.234472, Train accuracy: 0.617222, val accuracy: 0.600000\n",
      "Loss: 1.224784, Train accuracy: 0.650000, val accuracy: 0.621000\n",
      "Loss: 1.311690, Train accuracy: 0.677444, val accuracy: 0.644000\n",
      "Loss: 1.220182, Train accuracy: 0.701556, val accuracy: 0.654000\n",
      "Loss: 1.085442, Train accuracy: 0.698556, val accuracy: 0.671000\n",
      "Loss: 1.282627, Train accuracy: 0.748000, val accuracy: 0.694000\n",
      "Loss: 1.099136, Train accuracy: 0.721333, val accuracy: 0.686000\n",
      "Loss: 1.174271, Train accuracy: 0.760778, val accuracy: 0.706000\n",
      "Loss: 1.239753, Train accuracy: 0.765111, val accuracy: 0.712000\n",
      "Loss: 1.047013, Train accuracy: 0.784000, val accuracy: 0.728000\n",
      "Loss: 0.915551, Train accuracy: 0.775222, val accuracy: 0.704000\n",
      "Loss: 1.081031, Train accuracy: 0.802000, val accuracy: 0.739000\n",
      "Loss: 1.021305, Train accuracy: 0.754889, val accuracy: 0.685000\n",
      "Loss: 1.093791, Train accuracy: 0.783000, val accuracy: 0.708000\n",
      "Loss: 1.113084, Train accuracy: 0.810889, val accuracy: 0.732000\n",
      "Loss: 0.906421, Train accuracy: 0.822111, val accuracy: 0.742000\nbest validation accuracy achieved: 0.742000\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "learning_rates = 1e-1\n",
    "reg_strength = 1e-3\n",
    "learning_rate_decay = 0.99\n",
    "hidden_layer_size = 100\n",
    "num_epochs = 20\n",
    "batch_size = 200\n",
    "\n",
    "best_classifier = TwoLayerNet\n",
    "best_val_accuracy = None\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "# TODO find the best hyperparameters to train the network\n",
    "# Don't hesitate to add new values to the arrays above, perform experiments, use any tricks you want\n",
    "# You should expect to get to at least 40% of valudation accuracy\n",
    "# Save loss/train/history of the best classifier to the variables above\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = hidden_layer_size, reg = reg_strength)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), \n",
    "                  learning_rate = learning_rates, \n",
    "                  learning_rate_decay = learning_rate_decay, \n",
    "                  num_epochs = num_epochs, \n",
    "                  batch_size = batch_size)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "best_val_accuracy = np.max(val_history)\n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x5784508>]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 16
    },
    {
     "data": {
      "text/plain": "<Figure size 1080x504 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Neural net test set accuracy: 0.712000\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "test_pred = model.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}